{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MCP 서버 연결 (sse)\n",
    "- MCP 서버 수행 후 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_current_time', description='\\n    Get current time for the specified timezone.\\n    \\n    This function returns the current time for the specified timezone.\\n    If no timezone is specified, the default timezone is \"Asia/Seoul\".\\n\\n    Args:\\n        timezone (str): The timezone to get the current time for. Default is \"Asia/Seoul\".\\n\\n    Returns:\\n        str: A string containing the current time for the specified timezone.\\n    ', args_schema={'properties': {'timezone': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': 'Asia/Seoul', 'title': 'Timezone'}}, 'title': 'get_current_timeArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x16a71f2e0>)]\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "Current time in Asia/Seoul: 2025-05-08 15:39:41\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "현재 서울 시간은 2025년 5월 8일 오후 3시 39분 41초입니다.{'node': 'agent', 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'stop_reason': 'end_turn', 'stop_sequence': None}, id='run--24dd3f39-7f38-4a4d-b22c-fc7a5f2e207c', usage_metadata={'input_tokens': 537, 'output_tokens': 39, 'total_tokens': 576, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}), 'metadata': {'langgraph_step': 3, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:db9fcddc-c1b6-a242-0573-ce17253c022a', 'checkpoint_ns': 'agent:db9fcddc-c1b6-a242-0573-ce17253c022a', 'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'ls_max_tokens': 4096}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_teddynote.messages import ainvoke_graph, astream_graph\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "model = ChatAnthropic(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=4096,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            \"url\": \"http://localhost:8005/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    print(client.get_tools())\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    answer = await astream_graph(agent, {\"messages\": \"오늘 서울 시간을 알려줘\"})\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MCP 서버 연결 (stdio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_weather', description='\\n    Get current weather information for the specified location.\\n\\n    This function simulates a weather service by returning a fixed response.\\n    In a production environment, this would connect to a real weather API.\\n\\n    Args:\\n        location (str): The name of the location (city, region, etc.) to get weather for\\n\\n    Returns:\\n        str: A string containing the weather information for the specified location\\n    ', args_schema={'properties': {'location': {'title': 'Location', 'type': 'string'}}, 'required': ['location'], 'title': 'get_weatherArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x16a71f060>)]\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "The weather in 서울 is sunny.\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "서울의 날씨는 맑고 화창한 것 같습니다. 오늘은 야외 활동하기 좋은 날씨인 것 같네요."
     ]
    }
   ],
   "source": [
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Anthropic 모델 생성\n",
    "model = ChatAnthropic(\n",
    "    model_name=\"claude-3-haiku-20240307\",\n",
    "    max_tokens=4096,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# StdIO 서버 파라미터 설정\n",
    "# - command: Python 인터프리터 경로\n",
    "# - args: 실행할 MCP 서버 스크립트 경로\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"./.venv/bin/python\",\n",
    "    args=[\"01_mcp_server_local.py\"],\n",
    ")\n",
    "\n",
    "# StdIO 클라이언트를 사용하여 서버와 통신\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    # 클라이언트 세션 생성\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # 연결 초기화\n",
    "        await session.initialize()\n",
    "        \n",
    "        # 도구 로드\n",
    "        tools = await load_mcp_tools(session)\n",
    "        print(tools)\n",
    "        \n",
    "        # 에이전트 생성\n",
    "        agent = create_react_agent(model, tools)\n",
    "        \n",
    "        # 도구 호출\n",
    "        await astream_graph(agent, {\"messages\": \"오늘 서울의 날씨는 어때?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
